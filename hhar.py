# -*- coding: utf-8 -*-
"""projectMain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uu_ptMQaZcrpYlzh49OGzu9MXYNLGZrd
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd '/content/drive/My Drive/RT Project/'
import pandas as pd
data1 = pd.read_csv('data/Phones_accelerometer.csv')

import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler
from sklearn.preprocessing import LabelEncoder
from pylab import rcParams
from sklearn.metrics import confusion_matrix
from models import FullyConnectedNetwork,RecursiveNeuralNetwork

"""# Preprocess Data"""

def downSampleData(dataset, downsamplesize=100000):
  dataset = np.asarray(dataset)
  downSizeFeatureDatas = []
  yValue = ['bike','sit','stairsdown','stairsup','stand','walk']
  for output in yValue:
    typeIndex = np.where(dataset[:,4]==output)[0]
    downSizeFeatureIndex = np.random.choice(typeIndex, size=downsamplesize, replace=False)
    downSizeFeatureData = dataset[downSizeFeatureIndex]
    downSizeFeatureDatas.append(downSizeFeatureData)
  dataDown = np.concatenate((downSizeFeatureDatas[0],downSizeFeatureDatas[1],downSizeFeatureDatas[2],downSizeFeatureDatas[3],downSizeFeatureDatas[4],downSizeFeatureDatas[5]),axis=0)
  target = dataDown[:,4]
  feature = dataDown[:,0:3]

  for i in range(len(target)):
    target[i] = str(target[i])
  enc = LabelEncoder().fit(target)
  target = enc.transform(target)

  #to add userdetails to dataset
  userDetails = dataDown[:,3]
  for i in range(len(userDetails)):
    userDetails[i] = str(userDetails[i])
  userEnc = LabelEncoder().fit(userDetails)
  userDetails = userEnc.transform(userDetails)

  dataDown = np.concatenate((feature,userDetails[:,None]),axis=1)
  dataDown = np.concatenate((dataDown,target[:,None]),axis=1)
  return dataDown,target,enc.classes_

def preProcessData(processData,down_size):
  processData = processData.drop(labels = ['Arrival_Time','Creation_Time','Index', 'Model', 'Device'], axis=1)
  to_drop = ['null']	#To drop the null values from both data1 and data2
  processData = processData[~processData['gt'].isin(to_drop)]
  processData = processData.dropna()
  processData = processData.reset_index(drop=True)
  yData = processData['gt']
  dataDown = downSampleData(processData,100000)
  return dataDown

"""# Down Sample Data"""

downSampledData,yData,yDataLabels = preProcessData(data1,100000)

"""# Train and Test Split"""

batch_size = 100
test_split = .2
shuffle_dataset = True
random_seed= 42

# Creating data indices for training and validation splits:
dataset_size = len(downSampledData)
indices = list(range(dataset_size))
split = int(np.floor(test_split * dataset_size))
if shuffle_dataset :
    np.random.seed(random_seed)
    np.random.shuffle(indices)
train_indices, test_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(test_indices)

downSampledData=downSampledData.astype(float)
downSampledData = torch.from_numpy(downSampledData).float()


train_loader = torch.utils.data.DataLoader(downSampledData,batch_size=batch_size,sampler=train_sampler)
test_loader = torch.utils.data.DataLoader(downSampledData, batch_size=batch_size,sampler=valid_sampler)

"""# Fully Connected Network"""

noEpoch = 50
noInput = downSampledData.shape[1]-1
fnn = FullyConnectedNetwork(noEpoch,noInput)

"""## Train and Test Neural Network for different values of epoch

**Hyper Parameters**

1.   No of layers = 6
2.   BatchSize = 100
3.   Epoch = 0 to 50
4.   Learning Rate = 0.001
"""

trainAccuracy,testAccuracy = fnn.train(train_loader,test_loader)

"""## Model Accuracy Plot"""

rcParams['figure.figsize'] = 10, 4
import matplotlib.pyplot as plt
plt.plot(trainAccuracy)
plt.plot(testAccuracy)
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Model Loss Plot"""

rcParams['figure.figsize'] = 10, 4
import matplotlib.pyplot as plt
trainLoss = np.asarray(trainAccuracy)
trainLoss = 1-trainLoss
testLoss = np.asarray(testAccuracy)
testLoss = 1-testLoss
plt.plot(trainLoss)
plt.plot(testLoss)
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Test Net"""

yTrue,yPred,pred_fnn = fnn.predict(test_loader)

"""## Confusion Matrix"""

CM = confusion_matrix(yTrue, yPred)
from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=CM , figsize=(10, 6))
print(yDataLabels)
x=plt.xticks((0,1,2,3,4,5)  ,yDataLabels)
y=plt.yticks((0,1,2,3,4,5),yDataLabels)
plt.show()
print('yDataLabels ', yDataLabels)

"""# Recurrent Neural Network

### RNN Net
"""

downSampledData,yData,yDataLabels = preProcessData(data1,100000)
batch_size = 1000
test_split = .2
shuffle_dataset = True
random_seed= 42

# Creating data indices for training and validation splits:
dataset_size = len(downSampledData)
indices = list(range(dataset_size))
split = int(np.floor(test_split * dataset_size))
if shuffle_dataset :
    np.random.seed(random_seed)
    np.random.shuffle(indices)
train_indices, test_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(test_indices)

downSampledData=downSampledData.astype(float)
downSampledData = torch.from_numpy(downSampledData).float()


train_loader = torch.utils.data.DataLoader(downSampledData,batch_size=batch_size,sampler=train_sampler)
test_loader = torch.utils.data.DataLoader(downSampledData, batch_size=batch_size,sampler=valid_sampler)

"""## Train and Test Neural Network for different values of epoch

**Hyper Parameters**

1.   No of Neurons = 10
2.   BatchSize = 1000
3.   Epoch = 50
4.   Learning Rate = 0.01
"""

noOfNeurons = 10
epochs = 50
noOfInputs = 4

rnn = RecursiveNeuralNetwork(noOfInputs,noOfNeurons,epochs)
rtrain_acc,rtest_acc,rloss = rnn.train(train_loader,test_loader)
RNN_acc,RNN_targ,RNN_ypred = rnn.predict(test_loader)

"""## Test Net"""

RNN_acc,RNN_targ,RNN_ypred = rnn.predict(test_loader)

print(RNN_acc)

"""## Confusion Matrix"""

import matplotlib.pyplot as plt
CM = confusion_matrix(RNN_targ, RNN_ypred)
from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=CM , figsize=(10, 6))
print(yDataLabels)
x=plt.xticks((0,1,2,3,4,5)  ,yDataLabels)
y=plt.yticks((0,1,2,3,4,5),yDataLabels)
plt.show()
print('yDataLabels ', yDataLabels)